{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process events from the Watson IoT Platform in a Streams Python application\n",
    "\n",
    "If you have data being sent from a device to the Watson IoT platform, you can perform advanced analytics on such data using Python and the Streaming Analytics service.  This notebook shows a simple Python Streams application that connects to the Watson IoT platform to retrieve data sent there by an Edgent application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "***\n",
    "1.\t[Prerequisites](#setup)\n",
    "1.\t[Create and submit the Streams application](#streams)\n",
    "1.\t[View results](#view)\n",
    "1.  [Stop the application](#stop)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "# 1. Prerequisites\n",
    "\n",
    "\n",
    "This notebook is a companion to the [Connect Apache Edgent running on Raspberry Pi to the Streaming Analytics service recipe](https://developer.ibm.com/recipes/tutorials/connect-apache-edgent-to-the-streaming-analytics-service-using-the-watson-iot-platform/).\n",
    "\n",
    "\n",
    "It will show you a  Python Streams appliation that receives IoT device events from the Watson IoT platform. This is a Python version of the Java application demonstrated in that recipe. \n",
    " \n",
    "\n",
    "Therefore, it is assumed that you have completed steps 1-3 of the recipe. You should have the following:\n",
    "- An instance of the Watson IoT platform and the Streaming Analytics service\n",
    "- An Edgent application or other application that is registered with and sending events to the Watson IoT platform.\n",
    "- `IotPlatformBluemix` or `IotPlatform`  application running in your Streams instance\n",
    "\n",
    "If you are missing any of the above, please follow steps 1-3 of the recipe. Once you reach step 4, you may return to this notebook to continue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install the required version of the streamsx pacakge\n",
    "This notebook requires version 1.7 or later of the streamsx package.  \n",
    "Run the cell below to determine which version is installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip show streamsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the package if needed\n",
    "\n",
    "After running the above cell, you should see output like this:\n",
    "```\n",
    "---\n",
    "Metadata-Version: 2.0\n",
    "Name: streamsx\n",
    "Version: 1.7.4\n",
    "....\n",
    "```\n",
    "If the `Version` is not at or greater than 1.7, uncomment  and run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Comment out the line below if needed\n",
    "#!pip install --upgrade streamsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Create and submit the Streams application\n",
    "\n",
    "<a id=\"streams\"></a>\n",
    "### 2.1 Get your Streaming analytics service credentials\n",
    "Before you create an app with this notebook, you must first provide the information that your streaming app needs to access the service. You can find this information on the Streaming Analytics service dashboard. It includes the service name, the service credentials, and the connection URL for the service. \n",
    "In the next cell you have to enter your service credentials. To copy your service credentials, open the Streaming Analytics service dashboard click **Service Credentials**, then **View Credentials**, and finally click the Copy icon.\n",
    "\n",
    "<img src='https://github.com/orzade/streamsx-notebooks/blob/master/copyservicecredentials.png?raw=true' alt=\"Copy your service credentials\" title=\"Streaming Analytics catalog - Copy your service credentials\"></img>\n",
    "Then paste those credentials where indicated in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#Set up access to Streaming Analytics service\n",
    "\n",
    "def get_service_name():\n",
    "    ## change the service name here, it would be test1 in the screenshot above,\n",
    "    # and \"Streaming-Analytics\" if you used the IoT starter kit\n",
    "    service_name = \"service_name\" \n",
    "    return service_name\n",
    "def get_credentials():\n",
    "    credentials = \"\"\"Paste Credentials here\"\"\"\n",
    " \n",
    "    return credentials\n",
    "\n",
    "\n",
    "\"\"\"Submit the topology to the Streaming analytics service\n",
    "\"\"\"\n",
    "def submit_to_service(topo):\n",
    "    service_name = get_service_name()\n",
    "    credentials = get_credentials()\n",
    "    vs={'streaming-analytics': [{'name': service_name, 'credentials': json.loads (credentials)}]}\n",
    "    cfg = {}\n",
    "    cfg[ConfigParams.VCAP_SERVICES] = vs\n",
    "    cfg[ConfigParams.SERVICE_NAME] = service_name\n",
    "    return submit('STREAMING_ANALYTICS_SERVICE', topo, cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from streamsx.topology.topology import Topology\n",
    "from streamsx.topology.context import *\n",
    "from streamsx.rest import StreamingAnalyticsConnection\n",
    "from streamsx.topology import schema\n",
    "import random\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function will build the command tuple that is sent back\n",
    "to the Edgent application. \n",
    "The commands are JSON, and the format is:\n",
    "\n",
    "{\n",
    " 'deviceId': \"id of device receiving the command\",\n",
    "  'typeId': \"typeId of receiving device\",\n",
    "  'cmdId': \"some id\",\n",
    " 'jsonString': {'d':{command payload as JSON object}}\n",
    "}\n",
    "One way to get the device and type id is to use the data from an event we received\n",
    "the incoming tuple contains the event we are responding to\n",
    "\"\"\"\n",
    "def get_cmd(tuple):\n",
    "    #build the message you wish to send as a dictionary\n",
    "    payload = {}\n",
    "\n",
    "    payload[\"action\"] = \"Lights\"\n",
    "    payload[\"msg\"] = \"Message to Edgent from Streams\\n:Alert code: 249\"\n",
    "\n",
    "    command_data =  {}\n",
    "    command_data [\"d\"] = payload\n",
    "\n",
    "    #convert the whole payload to json\n",
    "    command_as_json = json.dumps(command_data)\n",
    "\n",
    "    #build the command metadata. The device id and device type are on the tuple, but you could also specify them manually\n",
    "    device_cmd ={}\n",
    "    device_cmd[\"typeId\"] = tuple[\"typeId\"]\n",
    "    device_cmd[\"cmdId\"] = \"display\"\n",
    "    device_cmd[\"deviceId\"] = tuple[\"deviceId\"]\n",
    "\n",
    "    device_cmd[\"jsonString\"] = command_as_json\n",
    "    return device_cmd\n",
    "\n",
    "\"\"\"Parse the data from an event we received\"\"\"\n",
    "def get_event_data(tuple):\n",
    "    payload_json = tuple[\"jsonString\"]\n",
    "    payload = json.loads(payload_json)\n",
    "    return payload[\"d\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.3 Create the Streams application\n",
    "\n",
    "### Application overview\n",
    "\n",
    "This application is going to process events from an IoT device running an Apache Edgent application. The application has a range sensor that is determines the physical distance of an object from the sensor.  It will send events whenever an object is less than 4m away from the sensor. It sends the average, max, minimum and stddev of the distance of the object for the last 10 readings. The events are of the form:\n",
    "```\n",
    "{\"name\":\"A\",\"reading\":{\"N\":2,\"MIN\":-2.384453313010427,\"MAX\":-2.0927794927623795,\"MEAN\":-2.2386164028864033,\"STDDEV\":0.20624453619198055}}\n",
    "```\n",
    "The Streams application will connect to the IoT platform to retrieve and print the events. Then it will also send a command back to the device to turn on the lights on the sensor. \n",
    "\n",
    "###  Create the Streams `Topology`\n",
    "\n",
    "Streams applications are directed graphs with data moving from one operation to the next. A Streams application written in Python is called a `Topology`. The `Topology` we are creating will start by ingesting the events from the device and printing them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from streamsx.topology.topology import Topology\n",
    "\n",
    "from streamsx.rest import StreamsConnection\n",
    "from streamsx.topology import schema\n",
    "import json\n",
    " #define needed variables\n",
    "COMMANDS_TOPIC = \"streamsx/iot/device/commands/send\" #topic to publish commands to\n",
    "EVENTS_TOPIC = \"streamsx/iot/device/events\" #topic to subscribe to for events\n",
    "incoming_schema =  schema.StreamSchema(\"tuple <rstring typeId, rstring deviceId, rstring eventId,rstring jsonString>\")\n",
    "cmd_schema = schema.StreamSchema('tuple<rstring typeId, rstring deviceId, rstring cmdId, rstring jsonString>')\n",
    "\n",
    "#Topology object is the Streams application graph\n",
    "topology = Topology('ReadingsFromIot')\n",
    "\n",
    "#Subscribe to  events\n",
    "events = topology.subscribe(EVENTS_TOPIC, incoming_schema,\"AllEventsAsJSON\")\n",
    "sensor_events = events.filter(lambda tuple: tuple[\"eventId\"] == \"sensors\",\"SensorEventsAsJSON\")\n",
    "readings = sensor_events.map(get_event_data,\"ReadingsStream\")\n",
    "#print out readings\n",
    "readings.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Send a response for each event\n",
    "Next, we will create a stream of commands to send back to the device. This is a very simple scenario, since we are not performing any major analysis but simply sending a response back for each event. Typically you could do more complex analysis, or connect to a database, e.t.c. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#send a command\n",
    "cmd_stream = sensor_events.map(get_cmd, \"CommandsAsJSON\")\n",
    "#convert the commands stream to a SPL structured schema\n",
    "commands_to_publish = cmd_stream.map(lambda x : (x[\"typeId\"],x[\"deviceId\"],x[\"cmdId\"],x[\"jsonString\"],), schema = cmd_schema, name=\"CommandsToPublish\")\n",
    "\n",
    "commands_to_publish.publish(COMMANDS_TOPIC, cmd_schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"submit_topo\"></a>\n",
    "#### 2.5 Submit the `Topology` to the Streaming Analytics service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = submit_to_service(topology)\n",
    "print(\"Submitted job to the service, job id = \" + str(result.job.id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"view\"></a>\n",
    "# 3. View the results\n",
    "\n",
    "#### View the events received from Edgent\n",
    "Since this application prints the received events from the Edgent application to the console. You can check the log viewer in the Streams Console to see the events received from the Edgent application\n",
    "\n",
    "#### View the commands sent back to Edgent\n",
    "You can view the output of the Edgent application to see that it does receive the commands from Streams. You should see messages like this:\n",
    "```\n",
    "Message to Edgent from Streams:\n",
    "Alert code: 249\n",
    "{\"name\":\"B\",\"reading\":{\"N\":50,\"MIN\":-2.762152936700155,\"MAX\":5.7895310031906675,\"MEAN\":2.239131357345944,\"STDDEV\":2.199931362960884}}\n",
    "Message to Edgent from Streams:\n",
    "Alert code: 249\n",
    "{\"name\":\"B\",\"reading\":{\"N\":50,\"MIN\":-2.762152936700155,\"MAX\":5.7895310031906675,\"MEAN\":2.127842287474011,\"STDDEV\":2.2555865482121846}}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stop\"></a>\n",
    "# 4. Stop the application\n",
    "From the Streams Console, cancel this application and the `IoTPlatform` job, otherwise they might run indefinitely, consuming resources in your service. If you cancel the job you need to [re-run cell 2.5](#submit_topo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Next Steps\n",
    "\n",
    "Now that you have a basic Python application ingesting IoT data and running in the Streaming Analytics service, you can \n",
    "\n",
    "- Try the \"Detect Malfunctioning Sensors\" notebook:\n",
    "    - [Watch the demo video on Youtube](https://www.youtube.com/watch?v=PDTSws6zULI), then \n",
    "    - [Try the notebook out yourself](https://ibm.biz/WeatherNotebook)\n",
    "- Learn more about developing Streaming Analytics applications in Python: \n",
    "  - Take the [Streaming Analytics for Python developers course](https://developer.ibm.com/courses/all/streaming-analytics-basics-python-developers/) on developerWorks.\n",
    "  - [Consult the Streams Python API Developer Guide](http://ibmstreams.github.io/streamsx.documentation/docs/python/1.6/python-appapi-devguide/)\n",
    "- For more Edgent and IoTP documentation, you can check out the [Edgent to Quickstart guide](http://edgent.incubator.apache.org/docs/quickstart.html).\n",
    "- Visit [Streamsdev, the Streams developer community](https://developer.ibm.com/streamsdev/), for more useful resources about Streams.\n",
    "\n",
    "Happy Streaming!\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Copyright © 2017 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.5 (Experimental) with Spark 2.0",
   "language": "python",
   "name": "python3-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
